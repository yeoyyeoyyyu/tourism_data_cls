{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yWXmXrzGjfn",
        "outputId": "620e676d-24f6-4b8d-9898-f1c0727e4e25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/sj/dacon/tourism_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhCXBjdRGxWq",
        "outputId": "2f018bd3-8f62-479f-9e32-193d893570cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/sj/dacon/tourism_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRV4s78ZtilC",
        "outputId": "54d72f78-32b1-4cd8-97df-3cbbba6e789a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.26.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "from tensorflow.image import pad_to_bounding_box, resize, random_crop, random_flip_left_right\n",
        "from keras.layers import Input, Dropout, Dense, GlobalAveragePooling2D, concatenate, BatchNormalization, Activation\n",
        "\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained('digit82/kobart-summarization')"
      ],
      "metadata": {
        "id": "R13E8LsZGtYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'IMG_SIZE': 224,\n",
        "    'EPOCHS':100,\n",
        "    'LEARNING_RATE':1e-3,\n",
        "    'BATCH_SIZE':32,\n",
        "    'SEED':41\n",
        "}"
      ],
      "metadata": {
        "id": "zqaFx3HHi72O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('train.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ooatEU3_coo5",
        "outputId": "8015cfd0-b5a2-4901-9617-32cebd309d50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                id                       img_path  \\\n",
              "0      TRAIN_00000  ./image/train/TRAIN_00000.jpg   \n",
              "1      TRAIN_00001  ./image/train/TRAIN_00001.jpg   \n",
              "2      TRAIN_00002  ./image/train/TRAIN_00002.jpg   \n",
              "3      TRAIN_00003  ./image/train/TRAIN_00003.jpg   \n",
              "4      TRAIN_00004  ./image/train/TRAIN_00004.jpg   \n",
              "...            ...                            ...   \n",
              "16981  TRAIN_16981  ./image/train/TRAIN_16981.jpg   \n",
              "16982  TRAIN_16982  ./image/train/TRAIN_16982.jpg   \n",
              "16983  TRAIN_16983  ./image/train/TRAIN_16983.jpg   \n",
              "16984  TRAIN_16984  ./image/train/TRAIN_16984.jpg   \n",
              "16985  TRAIN_16985  ./image/train/TRAIN_16985.jpg   \n",
              "\n",
              "                                                overview          cat1  \\\n",
              "0      소안항은 조용한 섬으로 인근해안이 청정해역으로 일찍이 김 양식을 해서 높은 소득을 ...            자연   \n",
              "1      경기도 이천시 모가면에 있는 골프장으로 대중제 18홀이다. 회원제로 개장을 했다가 ...           레포츠   \n",
              "2      금오산성숯불갈비는 한우고기만을 전문적으로 취급하고 사용하는 부식 자재 또한 유기농법...            음식   \n",
              "3      철판 위에서 요리하는 안동찜닭을 맛볼 수 있는 곳이다. 경상북도 안동시에 있는 한식...            음식   \n",
              "4      ※ 영업시간 10:30 ~ 20:30\\n\\n3대에 걸쳐 아귀만을 전문으로 취급하는 ...            음식   \n",
              "...                                                  ...           ...   \n",
              "16981  해발 12000m에 자리한 식담겸 카페점문점이다.<br>곤드레밥과 감자전을 판매하고...            음식   \n",
              "16982  설악힐호텔은 동해고속도로 속초톨게이트에서 멀지 않은 관광로 변에 있다. 속초의 대표...            숙박   \n",
              "16983  충남 서산시 중심가에 위치한 줌모텔은 프라이버스가 보장되는 조용한 공간으로 가치가 ...            숙박   \n",
              "16984  토토큰바위캠핑장은 경기도 가평지역 내에서도 청정지역으로 손꼽히는 지역으로 주변에 화...           레포츠   \n",
              "16985  포천의 진산으로 불리우는 왕방산(王訪山)에는 천년의 역사를 간직하고 있는 왕산사(王...  인문(문화/예술/역사)   \n",
              "\n",
              "         cat2       cat3  \n",
              "0       자연관광지      항구/포구  \n",
              "1      육상 레포츠         골프  \n",
              "2         음식점         한식  \n",
              "3         음식점         한식  \n",
              "4         음식점         한식  \n",
              "...       ...        ...  \n",
              "16981     음식점         한식  \n",
              "16982    숙박시설         모텔  \n",
              "16983    숙박시설         모텔  \n",
              "16984  육상 레포츠  야영장,오토캠핑장  \n",
              "16985   역사관광지         사찰  \n",
              "\n",
              "[16986 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-904ed04e-ac96-48ab-b189-8349c5bafd0d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>img_path</th>\n",
              "      <th>overview</th>\n",
              "      <th>cat1</th>\n",
              "      <th>cat2</th>\n",
              "      <th>cat3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TRAIN_00000</td>\n",
              "      <td>./image/train/TRAIN_00000.jpg</td>\n",
              "      <td>소안항은 조용한 섬으로 인근해안이 청정해역으로 일찍이 김 양식을 해서 높은 소득을 ...</td>\n",
              "      <td>자연</td>\n",
              "      <td>자연관광지</td>\n",
              "      <td>항구/포구</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TRAIN_00001</td>\n",
              "      <td>./image/train/TRAIN_00001.jpg</td>\n",
              "      <td>경기도 이천시 모가면에 있는 골프장으로 대중제 18홀이다. 회원제로 개장을 했다가 ...</td>\n",
              "      <td>레포츠</td>\n",
              "      <td>육상 레포츠</td>\n",
              "      <td>골프</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TRAIN_00002</td>\n",
              "      <td>./image/train/TRAIN_00002.jpg</td>\n",
              "      <td>금오산성숯불갈비는 한우고기만을 전문적으로 취급하고 사용하는 부식 자재 또한 유기농법...</td>\n",
              "      <td>음식</td>\n",
              "      <td>음식점</td>\n",
              "      <td>한식</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TRAIN_00003</td>\n",
              "      <td>./image/train/TRAIN_00003.jpg</td>\n",
              "      <td>철판 위에서 요리하는 안동찜닭을 맛볼 수 있는 곳이다. 경상북도 안동시에 있는 한식...</td>\n",
              "      <td>음식</td>\n",
              "      <td>음식점</td>\n",
              "      <td>한식</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TRAIN_00004</td>\n",
              "      <td>./image/train/TRAIN_00004.jpg</td>\n",
              "      <td>※ 영업시간 10:30 ~ 20:30\\n\\n3대에 걸쳐 아귀만을 전문으로 취급하는 ...</td>\n",
              "      <td>음식</td>\n",
              "      <td>음식점</td>\n",
              "      <td>한식</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16981</th>\n",
              "      <td>TRAIN_16981</td>\n",
              "      <td>./image/train/TRAIN_16981.jpg</td>\n",
              "      <td>해발 12000m에 자리한 식담겸 카페점문점이다.&lt;br&gt;곤드레밥과 감자전을 판매하고...</td>\n",
              "      <td>음식</td>\n",
              "      <td>음식점</td>\n",
              "      <td>한식</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16982</th>\n",
              "      <td>TRAIN_16982</td>\n",
              "      <td>./image/train/TRAIN_16982.jpg</td>\n",
              "      <td>설악힐호텔은 동해고속도로 속초톨게이트에서 멀지 않은 관광로 변에 있다. 속초의 대표...</td>\n",
              "      <td>숙박</td>\n",
              "      <td>숙박시설</td>\n",
              "      <td>모텔</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16983</th>\n",
              "      <td>TRAIN_16983</td>\n",
              "      <td>./image/train/TRAIN_16983.jpg</td>\n",
              "      <td>충남 서산시 중심가에 위치한 줌모텔은 프라이버스가 보장되는 조용한 공간으로 가치가 ...</td>\n",
              "      <td>숙박</td>\n",
              "      <td>숙박시설</td>\n",
              "      <td>모텔</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16984</th>\n",
              "      <td>TRAIN_16984</td>\n",
              "      <td>./image/train/TRAIN_16984.jpg</td>\n",
              "      <td>토토큰바위캠핑장은 경기도 가평지역 내에서도 청정지역으로 손꼽히는 지역으로 주변에 화...</td>\n",
              "      <td>레포츠</td>\n",
              "      <td>육상 레포츠</td>\n",
              "      <td>야영장,오토캠핑장</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16985</th>\n",
              "      <td>TRAIN_16985</td>\n",
              "      <td>./image/train/TRAIN_16985.jpg</td>\n",
              "      <td>포천의 진산으로 불리우는 왕방산(王訪山)에는 천년의 역사를 간직하고 있는 왕산사(王...</td>\n",
              "      <td>인문(문화/예술/역사)</td>\n",
              "      <td>역사관광지</td>\n",
              "      <td>사찰</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16986 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-904ed04e-ac96-48ab-b189-8349c5bafd0d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-904ed04e-ac96-48ab-b189-8349c5bafd0d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-904ed04e-ac96-48ab-b189-8349c5bafd0d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df['cat1'].value_counts().index), df['cat1'].value_counts().index)\n",
        "print(len(df['cat2'].value_counts().index), df['cat2'].value_counts().index)\n",
        "print(len(df['cat3'].value_counts().index), df['cat3'].value_counts().index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ux1a8ED-c4_1",
        "outputId": "f974986f-2691-40d1-f283-ad4479a97af0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6 Index(['인문(문화/예술/역사)', '음식', '레포츠', '자연', '숙박', '쇼핑'], dtype='object')\n",
            "18 Index(['음식점', '육상 레포츠', '자연관광지', '역사관광지', '숙박시설', '문화시설', '휴양관광지', '체험관광지',\n",
            "       '쇼핑', '축제', '건축/조형물', '수상 레포츠', '관광자원', '공연/행사', '산업관광지', '복합 레포츠',\n",
            "       '항공 레포츠', '레포츠소개'],\n",
            "      dtype='object')\n",
            "128 Index(['한식', '야영장,오토캠핑장', '바/까페', '유적지/사적지', '일반축제', '사찰', '이색거리', '펜션',\n",
            "       '한옥스테이', '모텔',\n",
            "       ...\n",
            "       '카지노', 'ATV', '빙벽등반', '발전소', '뮤지컬', 'MTB', '대중콘서트', '인라인(실내 인라인 포함)',\n",
            "       '스카이다이빙', '클래식음악회'],\n",
            "      dtype='object', length=128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_valid, _, _ = train_test_split(df, df['cat3'], test_size=0.2, random_state=config['SEED'])\n",
        "df_train.shape, df_valid.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0p2cwvmSqfrY",
        "outputId": "41ccacd5-c508-40e0-e9e3-ea2c4b48fd2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((13588, 6), (3398, 6))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for col in ['cat1', 'cat2', 'cat3']:\n",
        "    le = LabelEncoder()\n",
        "    le.fit(df[col].values)\n",
        "    df_train[col] = le.transform(df_train[col].values)\n",
        "    df_valid[col] = le.transform(df_valid[col].values)"
      ],
      "metadata": {
        "id": "X9Ky98zOrJdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dmg0xJHMq9m9",
        "outputId": "415c814d-4b81-4010-b829-9595b921ba8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                id                       img_path  \\\n",
              "1786   TRAIN_01786  ./image/train/TRAIN_01786.jpg   \n",
              "16670  TRAIN_16670  ./image/train/TRAIN_16670.jpg   \n",
              "3377   TRAIN_03377  ./image/train/TRAIN_03377.jpg   \n",
              "12814  TRAIN_12814  ./image/train/TRAIN_12814.jpg   \n",
              "2607   TRAIN_02607  ./image/train/TRAIN_02607.jpg   \n",
              "\n",
              "                                                overview  cat1  cat2  cat3  \n",
              "1786   함평양서파충류생태공원은 전남 함평군 신광면에 자리 잡고 있다. 공원 내에는 양서류를...     4     4    44  \n",
              "16670  국제수변레포츠 단지 내 위치한 충주 탄금호 캠핑 리조트는 다양한 문화체험이 가능한 ...     0    11    73  \n",
              "3377   경남 함양군 서하면에 위치한 함양 라온캠핑장은 마운틴뷰의 조용하고 깨끗한 신설 캠핑...     0    11    73  \n",
              "12814  캠프바베큐는 충남 천안시 동남구에 자리 잡고 있다. 천안시청을 기점으로 약 8㎞가량...     0    11    73  \n",
              "2607   원수산습지생태원은 세종시 연기면 세종리에 있다. 생태원 내에는 보존습지, 수생식물습...     5    13    93  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b843d97c-48ba-469d-9d99-4dda0e25dc2a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>img_path</th>\n",
              "      <th>overview</th>\n",
              "      <th>cat1</th>\n",
              "      <th>cat2</th>\n",
              "      <th>cat3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1786</th>\n",
              "      <td>TRAIN_01786</td>\n",
              "      <td>./image/train/TRAIN_01786.jpg</td>\n",
              "      <td>함평양서파충류생태공원은 전남 함평군 신광면에 자리 잡고 있다. 공원 내에는 양서류를...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16670</th>\n",
              "      <td>TRAIN_16670</td>\n",
              "      <td>./image/train/TRAIN_16670.jpg</td>\n",
              "      <td>국제수변레포츠 단지 내 위치한 충주 탄금호 캠핑 리조트는 다양한 문화체험이 가능한 ...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3377</th>\n",
              "      <td>TRAIN_03377</td>\n",
              "      <td>./image/train/TRAIN_03377.jpg</td>\n",
              "      <td>경남 함양군 서하면에 위치한 함양 라온캠핑장은 마운틴뷰의 조용하고 깨끗한 신설 캠핑...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12814</th>\n",
              "      <td>TRAIN_12814</td>\n",
              "      <td>./image/train/TRAIN_12814.jpg</td>\n",
              "      <td>캠프바베큐는 충남 천안시 동남구에 자리 잡고 있다. 천안시청을 기점으로 약 8㎞가량...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2607</th>\n",
              "      <td>TRAIN_02607</td>\n",
              "      <td>./image/train/TRAIN_02607.jpg</td>\n",
              "      <td>원수산습지생태원은 세종시 연기면 세종리에 있다. 생태원 내에는 보존습지, 수생식물습...</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>93</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b843d97c-48ba-469d-9d99-4dda0e25dc2a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b843d97c-48ba-469d-9d99-4dda0e25dc2a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b843d97c-48ba-469d-9d99-4dda0e25dc2a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(tf.data.Dataset):\n",
        "    # def __init__(self, img_path, text_vectors, label_list, transforms, infer=False):\n",
        "    def __init__(self, img_path, text, labels):\n",
        "        self.img_path = img_path\n",
        "        self.text = text\n",
        "        self.labels = labels\n",
        "        # self.transforms = transforms\n",
        "        # self.infer = infer\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        # NLP\n",
        "        text_vector = np.array(tokenizer.encode(self.text[index]), dtype=np.int32)\n",
        "        text_vector = tf.cast(text_vector, tf.float32)\n",
        "        # Image\n",
        "        img_path = self.img_path[index]\n",
        "        bin = tf.io.read_file(img_path)\n",
        "        image = tf.io.decode_png(bin, channels=3)\n",
        "        image = resize(image, size=(config['IMG_SIZE'], config['IMG_SIZE']))\n",
        "        image = tf.cast(image, tf.float32)\n",
        "        image /= 255\n",
        "        label = tf.cast(self.labels[index], tf.int32)\n",
        "        return (image, text_vector), label\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.img_path)\n",
        "    \n",
        "    def _inputs(self):\n",
        "        return []\n",
        "\n",
        "    def element_spec(self):\n",
        "        return (\n",
        "            tf.TensorSpec(shape=(None, None, 3), dtype=tf.float32, name='image'),\n",
        "            tf.TensorSpec(shape=(None,), dtype=tf.float32, name='text'),\n",
        "            tf.TensorSpec(shape=(), dtype=tf.int32, name='labels'),\n",
        "        )\n",
        "\n",
        "def generator():\n",
        "    for i in range(len(custom_dataset)):\n",
        "        yield custom_dataset[i]\n",
        "        \n",
        "custom_dataset = CustomDataset(df_train['img_path'].values, df_train['overview'].values, df_train['cat3'].values)\n",
        "dataset = tf.data.Dataset.from_generator(generator, output_types=(tf.float32, tf.float32, tf.int32))"
      ],
      "metadata": {
        "id": "HGKEeCC57W3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8njydejn9iHy",
        "outputId": "15c4ebe2-a8f9-4065-a95c-fbf91ad8e69f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<FlatMapDataset element_spec=(TensorSpec(shape=<unknown>, dtype=tf.float32, name=None), TensorSpec(shape=<unknown>, dtype=tf.float32, name=None), TensorSpec(shape=<unknown>, dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "This error is indicating that the structure of the elements being yielded by a generator in the TensorFlow code does not match the expected structure. Specifically, the expected structure is (tf.float32, tf.float32, tf.int32), but the yielded element was ((tf.Tensor(shape=(224, 224, 3), dtype=float32, numpy=...), tf.Tensor(shape=(109,), dtype=float32, numpy=...)).\n",
        "\n",
        "This could be caused by a variety of issues, such as the generator yielding data with the wrong shape or type, or the TensorFlow code expecting a different structure than what the generator is providing.\n",
        "\n",
        "To fix this error, you will need to inspect the code to identify where the generator is defined and how it is being used. You may need to modify the code to ensure that the generator yields elements with the expected structure.\n",
        "'''"
      ],
      "metadata": {
        "id": "wFCKEZozBcPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (image, overview), labels in dataset:\n",
        "    print(image.shape)\n",
        "    print(tokenizer.decode(overview))\n",
        "    print(labels)\n",
        "    plt.imshow(image)\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lfYcEUAP9f-R",
        "outputId": "0d8551da-d660-43ad-e8e7-3be169d6e41e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-c0d97231feba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    785\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;31m# to communicate that there is no more data to iterate over.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSYNC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m       ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[1;32m    771\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3015\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3016\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3017\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3018\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3019\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7213\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7214\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7215\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.float32, tf.int32), but the yielded element was ((<tf.Tensor: shape=(224, 224, 3), dtype=float32, numpy=\narray([[[0.12572584, 0.5453337 , 0.9923925 ],\n        [0.13188449, 0.54525983, 0.99543494],\n        [0.136861  , 0.5525473 , 0.99176294],\n        ...,\n        [0.4976453 , 0.76823354, 0.9918333 ],\n        [0.4979583 , 0.7685465 , 0.9999191 ],\n        [0.49395934, 0.76486415, 0.9879187 ]],\n\n       [[0.12994996, 0.5495578 , 0.9966166 ],\n        [0.13010813, 0.54547447, 0.9868634 ],\n        [0.14114146, 0.5568277 , 0.99604344],\n        ...,\n        [0.49690327, 0.7592402 , 0.98317784],\n        [0.5068778 , 0.7629614 , 0.99089783],\n        [0.50540745, 0.75875133, 0.99726015]],\n\n       [[0.12980567, 0.5517594 , 0.9917804 ],\n        [0.1337342 , 0.5494205 , 0.98863614],\n        [0.14117648, 0.54901963, 0.98438376],\n        ...,\n        [0.5019608 , 0.7607843 , 0.99607843],\n        [0.50000876, 0.76275384, 0.9784401 ],\n        [0.50159514, 0.767843  , 0.9800265 ]],\n\n       ...,\n\n       [[0.9365191 , 0.91142434, 0.83965796],\n        [0.95443314, 0.92895156, 0.8654046 ],\n        [0.94319844, 0.9157651 , 0.8491164 ],\n        ...,\n        [0.8881284 , 0.84499115, 0.7665598 ],\n        [0.8829959 , 0.8320155 , 0.7575057 ],\n        [0.89542025, 0.8428709 , 0.7683611 ]],\n\n       [[0.94752496, 0.9211748 , 0.8433625 ],\n        [0.9366606 , 0.9151747 , 0.8398596 ],\n        [0.9520626 , 0.90907925, 0.83058846],\n        ...,\n        [0.8758507 , 0.8327134 , 0.75428206],\n        [0.8274737 , 0.7764933 , 0.7019835 ],\n        [0.85680026, 0.80581987, 0.73131007]],\n\n       [[0.93826073, 0.9123854 , 0.8449484 ],\n        [0.9340578 , 0.90187997, 0.82898074],\n        [0.93045646, 0.9030055 , 0.8284957 ],\n        ...,\n        [0.80119747, 0.7580602 , 0.687472  ],\n        [0.78401864, 0.7408814 , 0.67029315],\n        [0.7706573 , 0.72752005, 0.6490887 ]]], dtype=float32)>, <tf.Tensor: shape=(109,), dtype=float32, numpy=\narray([14227., 20599., 11264., 13369., 12798., 10428., 24671.,  9115.,\n       14708., 16309., 14227., 13455.,  9173., 14094.,  9133., 18466.,\n       15219., 18398., 15964., 23593., 14067., 14147., 14256., 11264.,\n       17497., 16128., 14240., 12798., 10428.,   243., 14272., 11466.,\n       24231., 14382., 19827., 14058., 14139.,  8995., 13594., 14032.,\n       14082., 15983., 12034., 21080., 12159., 15964., 14188.,  9123.,\n       14147., 20158., 16231., 14112., 10295., 15188., 16128., 14255.,\n       10607., 15779., 14214.,  9006., 27283., 14382., 19827., 13594.,\n       14032., 15964., 29559.,  9123., 14147., 20581., 10806.,   243.,\n       14045.,  9237.,  9123., 14147., 14850., 11763.,  9031., 10949.,\n       14720., 22165., 12007., 19389., 21158., 14121., 10496., 10806.,\n         243., 14025.,  9170., 11696.,  9495., 19827., 14191.,   243.,\n       14272., 11466., 24231., 14630.,  9264., 21488., 14624., 15959.,\n       18323.,  9866., 14712.,  9895., 15964.], dtype=float32)>), <tf.Tensor: shape=(), dtype=int32, numpy=44>).\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1045, in generator_py_func\n    flattened_values = nest.flatten_up_to(output_types, values)\n\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/util/nest.py\", line 377, in flatten_up_to\n    assert_shallow_structure(shallow_tree, input_tree)\n\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/util/nest.py\", line 289, in assert_shallow_structure\n    raise ValueError(\n\nValueError: The two structures don't have the same sequence length. Input structure has length 2, while shallow structure has length 3.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/ops/script_ops.py\", line 271, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1047, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.float32, tf.int32), but the yielded element was ((<tf.Tensor: shape=(224, 224, 3), dtype=float32, numpy=\narray([[[0.12572584, 0.5453337 , 0.9923925 ],\n        [0.13188449, 0.54525983, 0.99543494],\n        [0.136861  , 0.5525473 , 0.99176294],\n        ...,\n        [0.4976453 , 0.76823354, 0.9918333 ],\n        [0.4979583 , 0.7685465 , 0.9999191 ],\n        [0.49395934, 0.76486415, 0.9879187 ]],\n\n       [[0.12994996, 0.5495578 , 0.9966166 ],\n        [0.13010813, 0.54547447, 0.9868634 ],\n        [0.14114146, 0.5568277 , 0.99604344],\n        ...,\n        [0.49690327, 0.7592402 , 0.98317784],\n        [0.5068778 , 0.7629614 , 0.99089783],\n        [0.50540745, 0.75875133, 0.99726015]],\n\n       [[0.12980567, 0.5517594 , 0.9917804 ],\n        [0.1337342 , 0.5494205 , 0.98863614],\n        [0.14117648, 0.54901963, 0.98438376],\n        ...,\n        [0.5019608 , 0.7607843 , 0.99607843],\n        [0.50000876, 0.76275384, 0.9784401 ],\n        [0.50159514, 0.767843  , 0.9800265 ]],\n\n       ...,\n\n       [[0.9365191 , 0.91142434, 0.83965796],\n        [0.95443314, 0.92895156, 0.8654046 ],\n        [0.94319844, 0.9157651 , 0.8491164 ],\n        ...,\n        [0.8881284 , 0.84499115, 0.7665598 ],\n        [0.8829959 , 0.8320155 , 0.7575057 ],\n        [0.89542025, 0.8428709 , 0.7683611 ]],\n\n       [[0.94752496, 0.9211748 , 0.8433625 ],\n        [0.9366606 , 0.9151747 , 0.8398596 ],\n        [0.9520626 , 0.90907925, 0.83058846],\n        ...,\n        [0.8758507 , 0.8327134 , 0.75428206],\n        [0.8274737 , 0.7764933 , 0.7019835 ],\n        [0.85680026, 0.80581987, 0.73131007]],\n\n       [[0.93826073, 0.9123854 , 0.8449484 ],\n        [0.9340578 , 0.90187997, 0.82898074],\n        [0.93045646, 0.9030055 , 0.8284957 ],\n        ...,\n        [0.80119747, 0.7580602 , 0.687472  ],\n        [0.78401864, 0.7408814 , 0.67029315],\n        [0.7706573 , 0.72752005, 0.6490887 ]]], dtype=float32)>, <tf.Tensor: shape=(109,), dtype=float32, numpy=\narray([14227., 20599., 11264., 13369., 12798., 10428., 24671.,  9115.,\n       14708., 16309., 14227., 13455.,  9173., 14094.,  9133., 18466.,\n       15219., 18398., 15964., 23593., 14067., 14147., 14256., 11264.,\n       17497., 16128., 14240., 12798., 10428.,   243., 14272., 11466.,\n       24231., 14382., 19827., 14058., 14139.,  8995., 13594., 14032.,\n       14082., 15983., 12034., 21080., 12159., 15964., 14188.,  9123.,\n       14147., 20158., 16231., 14112., 10295., 15188., 16128., 14255.,\n       10607., 15779., 14214.,  9006., 27283., 14382., 19827., 13594.,\n       14032., 15964., 29559.,  9123., 14147., 20581., 10806.,   243.,\n       14045.,  9237.,  9123., 14147., 14850., 11763.,  9031., 10949.,\n       14720., 22165., 12007., 19389., 21158., 14121., 10496., 10806.,\n         243., 14025.,  9170., 11696.,  9495., 19827., 14191.,   243.,\n       14272., 11466., 24231., 14630.,  9264., 21488., 14624., 15959.,\n       18323.,  9866., 14712.,  9895., 15964.], dtype=float32)>), <tf.Tensor: shape=(), dtype=int32, numpy=44>).\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generator_train():\n",
        "    for item in df_train.values:\n",
        "        yield (item[1], item[2], item[3:])\n",
        "\n",
        "def generator_valid():\n",
        "    for item in df_valid.values:\n",
        "        yield (item[1], item[2], item[3:])\n",
        "    \n",
        "dataset_train = tf.data.Dataset.from_generator(\n",
        "    generator_train,\n",
        "    (tf.string, tf.string, tf.int32),\n",
        "    ((), (), (3,))\n",
        "    )\n",
        "\n",
        "dataset_valid = tf.data.Dataset.from_generator(\n",
        "    generator_valid,\n",
        "    (tf.string, tf.string, tf.int32),\n",
        "    ((), (), (3,))\n",
        "    )\n",
        "\n",
        "def augmentation(image):\n",
        "    h, w = image.shape[0], image.shape[1]\n",
        "    size = h if h > w else w\n",
        "    dst = pad_to_bounding_box(image, int((size-h)/2), int((size-w)/2), size, size)\n",
        "    dst = resize(dst, size=(config['IMG_SIZE'], config['IMG_SIZE']))\n",
        "\n",
        "    dst = random_flip_left_right(dst)\n",
        "    dst = tf.cast(dst, tf.float32)\n",
        "    dst /= 255\n",
        "\n",
        "    return dst\n",
        "\n",
        "def encoding(text):\n",
        "    return tokenizer.encode(text)\n",
        "\n",
        "def preprocessing(path, overview, labels):\n",
        "    bin = tf.io.read_file(path)\n",
        "    image = tf.io.decode_png(bin, channels=3)\n",
        "    image = tf.py_function(augmentation, [image], [tf.float32])\n",
        "    image = tf.squeeze(image)\n",
        "\n",
        "    vector = tf.py_function(encoding, [overview], [tf.int32])\n",
        "    return (image, vector), labels\n",
        "\n",
        "dt = dataset_train.map(preprocessing, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "dt = dt.batch(config['BATCH_SIZE']).prefetch(3)\n",
        "dv = dataset_valid.map(preprocessing, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "dv = dv.batch(config['BATCH_SIZE']).prefetch(3)"
      ],
      "metadata": {
        "id": "swkkwr-9dDUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (image, overview), labels in dt.take(1):\n",
        "    print(image[0].shape)\n",
        "    print(tokenizer.decode(overview[0]))\n",
        "    print(labels[0])\n",
        "    plt.imshow(image[0])\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 997
        },
        "id": "TyulyLBwztT9",
        "outputId": "41ac7bf6-405a-4d76-de39-268413562a7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-4518b010ecdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverview\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    785\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;31m# to communicate that there is no more data to iterate over.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSYNC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m       ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[1;32m    771\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3015\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3016\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3017\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3018\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3019\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7213\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7214\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7215\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} TypeError: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    return func(device, token, args)\n\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/ops/script_ops.py\", line 147, in __call__\n    outputs = self._call(device, args)\n\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/ops/script_ops.py\", line 154, in _call\n    ret = self._func(*args)\n\n  File \"/usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"<ipython-input-21-c3a66e86d6d9>\", line 34, in encoding\n    return tokenizer.encode(text)\n\n  File \"/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py\", line 2294, in encode\n    encoded_inputs = self.encode_plus(\n\n  File \"/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_base.py\", line 2702, in encode_plus\n    return self._encode_plus(\n\n  File \"/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_fast.py\", line 502, in _encode_plus\n    batched_output = self._batch_encode_plus(\n\n  File \"/usr/local/lib/python3.9/dist-packages/transformers/tokenization_utils_fast.py\", line 429, in _batch_encode_plus\n    encodings = self._tokenizer.encode_batch(\n\nTypeError: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]\n\n\n\t [[{{node EagerPyFunc_1}}]] [Op:IteratorGetNext]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(tokenizer.encode(df.values[0][2]), dtype=np.int32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7EHLVrx_zk7",
        "outputId": "8ef5d75d-3934-46f9-aa54-a94757fdef27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([14081, 11699, 13603, 12005, 18478, 13590, 16020, 14027, 16110,\n",
              "       13607, 16789, 14249, 12141, 13607, 24410, 19509, 12034, 14116,\n",
              "       14256, 14649, 15709, 14904, 16365, 12007, 24294, 16390, 17017,\n",
              "        9497, 11465, 13173, 22447, 15885, 22564, 14577, 22225, 23057,\n",
              "       26341, 12074, 14167, 16020, 17726, 14180, 20127, 10281, 13590,\n",
              "       14923, 14508, 22777,  1700, 18507, 20529, 16390, 14055, 10612,\n",
              "       14089, 16020, 12024, 14045, 18698, 17017, 12024, 21076, 15065,\n",
              "       15673, 26957, 14082, 14937, 22564, 21931, 16020, 14147, 14319,\n",
              "       11465, 11802, 24381,   243, 26031, 10769, 11973, 14624, 14193,\n",
              "       15693, 15750, 15199, 19174, 16127, 16908, 14045, 11940, 15046,\n",
              "       11763, 12147, 15046, 11320, 12034, 21593, 15964,   259,   297,\n",
              "         313,   261], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(tokenizer.encode(df.values[0][2]))"
      ],
      "metadata": {
        "id": "YALZgrtwzoqu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}